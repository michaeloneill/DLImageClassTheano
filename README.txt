
Python modules Required to run the code (version number on RHS):

cycler==0.10.0
funcsigs==1.0.2
matplotlib==1.4.3
mock==2.0.0
nose==1.3.7
numpy==1.10.1
pbr==1.10.0
Pillow==3.2.0
pyparsing==2.1.5
python-dateutil==2.5.3
pytz==2016.4
scipy==0.16.0
six==1.10.0
Theano==0.7.0


To install all the requirements quickly and easily:

create a virtual envoronment with the DeepLeearning folder (http://docs.python-guide.org/en/latest/dev/virtualenvs/)
Copy and paste the above list (exactly) into a new file requirements.txt
From within the virtual environment run:  pip freeze > requirements.txt


########################################################################################################################################

Follow the steps below to test the code on the raw SAT-4 dataset that we used in the project. Note that this requires ~20GB RAM (tycho in the LSC can handle this).

STEP 1) Download the dataset sat-4-full.mat from http://csc.lsu.edu/~saikat/deepsat/
This is the raw version of the SAT-4 datset we used in the report

STEP 2) Create a new directory DeepLearning/common/datasets/sat4-sat6/ and store sat-4-full.mat in there

STEP 3)

FOR TESTING THE CNN:

Navigate to DeepLearning/common and run:
python generate_datasets.py
This will create a file DeepLearning/common/datasets/sat4-sat6/sat4_scaled_rastered.npz which holds the data in sat-4-full.mat in a suitable format for our CNN algorithm
This will take 5-10mins
By commenting sat4_rastered(to_file=True) and uncommenting sat4_ZCA(), a ZCA pre-processed version can be generated.

FOR TESTING THE MLP, SDA or DBN:

Comment out the line sat4_rastered(to_file=True) in generate_datasets.py and uncomment the line sat4_unroll(to_file=True)
Now run python generate_datasets.py again
This will create a file DeepLearning/common/datasets/sat4-sat6/sat4_scaled_unrolled.npz which holds the data in sat-4-full.mat in a suitable format for our MLP, SDA and DBN algorithms
This will take 5-10mins

STEP 4) The .npz files created in step 3 are ~10GB. They can now be moved into any directory that has enough space to hold them e.g. /local/data

STEP 5) Navigate to either the cnn, MLP, sdA or dbn directory in the DeepLearning root directory, depending on which model you want to run.

STEP 7) Create a results directory to hold the output files that will be generated by running the models e.g. DeepLearning/cnn/results/

STEP 8) Run the model with, for example:
python cnn.py -d <path/to/data_file.npz> -r <path/to/results_directory>
Training and optimisation paramters can be specified in the main() function
To run the code on a GPU, the commands are preceded by the flags THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32
Training progress can be monitored via output on the terminal
At the prompt, choose whether to save the model after training has completed


###########################################################################################################################################################

A saved model can be loaded back in for further training/testing as new data becomes available. We can demonstrate this functionality as follows:

Modify generate_datasets.py so that ONLY X_train and y_train are saved to the .npz file and change the outFilename to './datasets/sat4-sat6/test_data_file.npz'

Assumming steps 1-8 have been followed above and the model has been saved as model_file.pkl, we can now run:

python cnn.py -d <path/to/test_data_file.npz> -m <path/to/model_file.pkl>

Results will be displayed in a variety of ways using the plotting functions from plotting.py

